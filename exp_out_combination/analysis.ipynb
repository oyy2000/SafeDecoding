{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mistral\n",
      "                                                                  HEx-PHI  \\\n",
      "LayerBugFixer+Paraphrase       0.00 (0.00%) (0.00%)\\n0.00 (0.00%) (0.00%)   \n",
      "Unlearning+Self-Exam                                1.92 (0.00%) (43.10%)   \n",
      "SafeDecoding+Paraphrase                             3.07 (0.00%) (67.93%)   \n",
      "LayerBugFixer+Self-Exam       2.15 (0.00%) (39.66%)\\n0.00 (0.00%) (0.00%)   \n",
      "Unlearning+Paraphrase                                0.00 (0.00%) (0.00%)   \n",
      "SafeDecoding+Self-Exam                              3.01 (0.00%) (67.93%)   \n",
      "Retokenization+LayerBugFixer                                          NaN   \n",
      "\n",
      "                                                                           MMLU  \\\n",
      "LayerBugFixer+Paraphrase                                                    NaN   \n",
      "Unlearning+Self-Exam                                                        NaN   \n",
      "SafeDecoding+Paraphrase                                                     NaN   \n",
      "LayerBugFixer+Self-Exam                                                     NaN   \n",
      "Unlearning+Paraphrase                                                       NaN   \n",
      "SafeDecoding+Self-Exam                                                      NaN   \n",
      "Retokenization+LayerBugFixer  0.00 (0.00%) (0.00%)\\n0.00 (0.00%) (0.00%)\\n0....   \n",
      "\n",
      "                                         Just-Eval           DeepInception  \\\n",
      "LayerBugFixer+Paraphrase      0.00 (0.00%) (0.00%)    0.00 (0.00%) (0.00%)   \n",
      "Unlearning+Self-Exam                           NaN   2.94 (0.00%) (60.00%)   \n",
      "SafeDecoding+Paraphrase       0.00 (0.00%) (0.00%)  4.40 (0.00%) (100.00%)   \n",
      "LayerBugFixer+Self-Exam       0.00 (0.00%) (0.00%)   3.20 (0.00%) (68.00%)   \n",
      "Unlearning+Paraphrase         0.00 (0.00%) (0.00%)    0.00 (0.00%) (0.00%)   \n",
      "SafeDecoding+Self-Exam        0.00 (0.00%) (0.00%)  4.40 (0.00%) (100.00%)   \n",
      "Retokenization+LayerBugFixer                   NaN                     NaN   \n",
      "\n",
      "                                                GCG  \\\n",
      "LayerBugFixer+Paraphrase       0.00 (0.00%) (0.00%)   \n",
      "Unlearning+Self-Exam          1.37 (0.00%) (21.15%)   \n",
      "SafeDecoding+Paraphrase       3.76 (0.00%) (90.38%)   \n",
      "LayerBugFixer+Self-Exam       1.43 (0.00%) (21.15%)   \n",
      "Unlearning+Paraphrase          0.00 (0.00%) (0.00%)   \n",
      "SafeDecoding+Self-Exam        3.81 (0.00%) (90.38%)   \n",
      "Retokenization+LayerBugFixer  2.52 (0.00%) (81.73%)   \n",
      "\n",
      "                                                                 AdvBench  \\\n",
      "LayerBugFixer+Paraphrase                                              NaN   \n",
      "Unlearning+Self-Exam          0.00 (0.00%) (0.00%)\\n1.62 (0.00%) (33.65%)   \n",
      "SafeDecoding+Paraphrase                                               NaN   \n",
      "LayerBugFixer+Self-Exam                             1.41 (0.00%) (21.15%)   \n",
      "Unlearning+Paraphrase                                0.00 (0.00%) (0.00%)   \n",
      "SafeDecoding+Self-Exam        0.00 (0.00%) (0.00%)\\n3.19 (0.00%) (75.00%)   \n",
      "Retokenization+LayerBugFixer                                          NaN   \n",
      "\n",
      "                                                PAIR  \n",
      "LayerBugFixer+Paraphrase        0.00 (0.00%) (0.00%)  \n",
      "Unlearning+Self-Exam           1.52 (0.00%) (20.83%)  \n",
      "SafeDecoding+Paraphrase       4.40 (0.00%) (100.00%)  \n",
      "LayerBugFixer+Self-Exam        1.71 (0.00%) (25.00%)  \n",
      "Unlearning+Paraphrase           0.00 (0.00%) (0.00%)  \n",
      "SafeDecoding+Self-Exam        4.42 (0.00%) (100.00%)  \n",
      "Retokenization+LayerBugFixer                     NaN  \n",
      "Model: llama2\n",
      "                                      AdvBench\n",
      "LayerBugFixer+Self-Exam   0.00 (0.00%) (0.00%)\n",
      "Unlearning+Paraphrase     0.00 (0.00%) (0.00%)\n",
      "LayerBugFixer+Paraphrase  0.00 (0.00%) (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from statistics import mean\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化一个字典来存储每个 model 的数据\n",
    "model_data = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "def parse_filename(file_name):\n",
    "    \"\"\"从文件名中解析 defender、model_name、attacker、num_prompts 和 time_str\"\"\"\n",
    "    parts = file_name.split('_')\n",
    "    defender = parts[0]  # 第一部分是 defender\n",
    "    model_name = parts[1]\n",
    "    attacker = parts[2]\n",
    "    num_prompts = parts[3]\n",
    "    time_str = parts[4]\n",
    "    return defender, model_name, attacker, num_prompts, time_str\n",
    "\n",
    "def process_folder(folder_path, file_name):\n",
    "    gpt_scores = []\n",
    "    dic_score_false_count = 0\n",
    "    eval_res_label_1_count = 0\n",
    "    total_entries = 0\n",
    "    \n",
    "    # 找到以 _safe_eval.json 结尾的文件\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('_safe_eval.json'):\n",
    "            safe_eval_file = os.path.join(folder_path, file)\n",
    "            with open(safe_eval_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # 确保 data 是一个列表\n",
    "                if isinstance(data, list):\n",
    "                    for entry in data:\n",
    "                        # 统计 GPT_score 平均值\n",
    "                        if \"GPT_score\" in entry:\n",
    "                            gpt_scores.append(entry[\"GPT_score\"])\n",
    "\n",
    "                        # 统计 dic_score 为 false 的占比\n",
    "                        if \"dic_score\" in entry and entry[\"dic_score\"] is False:\n",
    "                            dic_score_false_count += 1\n",
    "\n",
    "                        # 统计 eval_res 中 label 等于 \"LABEL_1\" 的比例\n",
    "                        if \"eval_res\" in entry:\n",
    "                            if entry.get(\"label\") == \"LABEL_1\":\n",
    "                                eval_res_label_1_count += 1\n",
    "    \n",
    "    # 计算结果\n",
    "    avg_gpt_score = mean(gpt_scores) if gpt_scores else 0\n",
    "    dic_score_false_ratio = dic_score_false_count / len(gpt_scores) if gpt_scores else 0\n",
    "    label_1_ratio = eval_res_label_1_count / total_entries if total_entries else 0\n",
    "    \n",
    "    # 将结果保存到相应的 model、defender 和 attacker\n",
    "    defender, model_name, attacker, num_prompts, time_str = parse_filename(file_name)\n",
    "    model_data[model_name][defender][attacker].append({\n",
    "        \"num_prompts\": num_prompts,\n",
    "        \"time_str\": time_str,\n",
    "        \"average_GPT_score\": avg_gpt_score,\n",
    "        \"dic_score_false_ratio\": dic_score_false_ratio,\n",
    "        \"label_1_ratio\": label_1_ratio\n",
    "    })\n",
    "\n",
    "# Function to create the summary table\n",
    "def create_summary_table(data):\n",
    "    # 创建一个空的数据框\n",
    "    columns = set()\n",
    "    rows = set()\n",
    "    \n",
    "    # 首先收集所有的 defender 和 attacker 名称\n",
    "    for defender, attackers in data.items():\n",
    "        rows.add(defender)\n",
    "        for attacker in attackers.keys():\n",
    "            columns.add(attacker)\n",
    "    \n",
    "    # 创建一个 pandas DataFrame\n",
    "    table = pd.DataFrame(index=list(rows), columns=list(columns))\n",
    "    \n",
    "    # 填充表格数据\n",
    "    for defender, attackers in data.items():\n",
    "        for attacker, entries in attackers.items():\n",
    "            cell_data = []\n",
    "            for entry in entries:\n",
    "                avg_gpt_score = entry['average_GPT_score']\n",
    "                label_1_ratio = entry['label_1_ratio'] * 100  # 转换为百分比\n",
    "                dic_score_false_ratio = entry['dic_score_false_ratio'] * 100  # 转换为百分比\n",
    "                # 格式化成所需的字符串\n",
    "                cell_data.append(f\"{avg_gpt_score:.2f} ({label_1_ratio:.2f}%) ({dic_score_false_ratio:.2f}%)\")\n",
    "            \n",
    "            # 将数据放到表格的单元格里\n",
    "            table.at[defender, attacker] = \"\\n\".join(cell_data)\n",
    "    \n",
    "    return table\n",
    "# 遍历主文件夹中的所有子文件夹并处理\n",
    "base_dir = '/home/kz34/Yang_Ouyang_Projects/ICLR2025/jailbreaking_related/SafeDecoding/exp_out_combination'\n",
    "\n",
    "for folder in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        if folder == 'previous_result':\n",
    "            continue\n",
    "        process_folder(folder_path, folder)\n",
    "\n",
    "# 为每个 model_name 创建并保存表格\n",
    "for model_name, defenders in model_data.items():\n",
    "    summary_table = create_summary_table(defenders)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(summary_table)\n",
    "    \n",
    "    # 将结果保存为 excel 文件\n",
    "    summary_table.to_csv(f'{model_name}_defender_attacker_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdvBench_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
