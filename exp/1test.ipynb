{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "# Define choices for multiple-choice questions\n",
    "CHOICES = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# Mappings from subcategories to categories\n",
    "SUBCATEGORIES = {\n",
    "    \"abstract_algebra\": [\"math\"],\n",
    "    \"anatomy\": [\"health\"],\n",
    "    \"astronomy\": [\"physics\"],\n",
    "    \"business_ethics\": [\"business\"],\n",
    "    \"clinical_knowledge\": [\"health\"],\n",
    "    \"college_biology\": [\"biology\"],\n",
    "    \"college_chemistry\": [\"chemistry\"],\n",
    "    \"college_computer_science\": [\"computer science\"],\n",
    "    \"college_mathematics\": [\"math\"],\n",
    "    \"college_medicine\": [\"health\"],\n",
    "    \"college_physics\": [\"physics\"],\n",
    "    \"computer_security\": [\"computer science\"],\n",
    "    \"conceptual_physics\": [\"physics\"],\n",
    "    \"econometrics\": [\"economics\"],\n",
    "    \"electrical_engineering\": [\"engineering\"],\n",
    "    \"elementary_mathematics\": [\"math\"],\n",
    "    \"formal_logic\": [\"philosophy\"],\n",
    "    \"global_facts\": [\"other\"],\n",
    "    \"high_school_biology\": [\"biology\"],\n",
    "    \"high_school_chemistry\": [\"chemistry\"],\n",
    "    \"high_school_computer_science\": [\"computer science\"],\n",
    "    \"high_school_european_history\": [\"history\"],\n",
    "    \"high_school_geography\": [\"geography\"],\n",
    "    \"high_school_government_and_politics\": [\"politics\"],\n",
    "    \"high_school_macroeconomics\": [\"economics\"],\n",
    "    \"high_school_mathematics\": [\"math\"],\n",
    "    \"high_school_microeconomics\": [\"economics\"],\n",
    "    \"high_school_physics\": [\"physics\"],\n",
    "    \"high_school_psychology\": [\"psychology\"],\n",
    "    \"high_school_statistics\": [\"math\"],\n",
    "    \"high_school_us_history\": [\"history\"],\n",
    "    \"high_school_world_history\": [\"history\"],\n",
    "    \"human_aging\": [\"health\"],\n",
    "    \"human_sexuality\": [\"culture\"],\n",
    "    \"international_law\": [\"law\"],\n",
    "    \"jurisprudence\": [\"law\"],\n",
    "    \"logical_fallacies\": [\"philosophy\"],\n",
    "    \"machine_learning\": [\"computer science\"],\n",
    "    \"management\": [\"business\"],\n",
    "    \"marketing\": [\"business\"],\n",
    "    \"medical_genetics\": [\"health\"],\n",
    "    \"miscellaneous\": [\"other\"],\n",
    "    \"moral_disputes\": [\"philosophy\"],\n",
    "    \"moral_scenarios\": [\"philosophy\"],\n",
    "    \"nutrition\": [\"health\"],\n",
    "    \"philosophy\": [\"philosophy\"],\n",
    "    \"prehistory\": [\"history\"],\n",
    "    \"professional_accounting\": [\"other\"],\n",
    "    \"professional_law\": [\"law\"],\n",
    "    \"professional_medicine\": [\"health\"],\n",
    "    \"professional_psychology\": [\"psychology\"],\n",
    "    \"public_relations\": [\"politics\"],\n",
    "    \"security_studies\": [\"politics\"],\n",
    "    \"sociology\": [\"culture\"],\n",
    "    \"us_foreign_policy\": [\"politics\"],\n",
    "    \"virology\": [\"health\"],\n",
    "    \"world_religions\": [\"philosophy\"],\n",
    "}\n",
    "\n",
    "# Mappings from categories to higher-level categories\n",
    "CATEGORIES = {\n",
    "    \"STEM\": [\"physics\", \"chemistry\", \"biology\", \"computer science\", \"math\", \"engineering\"],\n",
    "    \"humanities\": [\"history\", \"philosophy\", \"law\"],\n",
    "    \"social sciences\": [\"politics\", \"culture\", \"economics\", \"geography\", \"psychology\"],\n",
    "    \"other (business, health, misc.)\": [\"other\", \"business\", \"health\"],\n",
    "}\n",
    "\n",
    "def format_subject(subject):\n",
    "    \"\"\"\n",
    "    Formats the subject name by replacing underscores with spaces.\n",
    "\n",
    "    Args:\n",
    "        subject (str): The subject name with underscores.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted subject name.\n",
    "    \"\"\"\n",
    "    return \" \".join(subject.split(\"_\")).strip()\n",
    "\n",
    "def format_example(df, idx, include_answer=True):\n",
    "    \"\"\"\n",
    "    Formats a single example from the dataframe into a prompt string.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        idx (int): Index of the example in the DataFrame.\n",
    "        include_answer (bool): Whether to include the answer in the prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted prompt string.\n",
    "    \"\"\"\n",
    "    prompt = df.iloc[idx, 0]\n",
    "    num_choices = df.shape[1] - 2  # Assuming last column is the answer\n",
    "    for j in range(num_choices):\n",
    "        prompt += f\"\\n{CHOICES[j]}. {df.iloc[idx, j + 1]}\"\n",
    "    prompt += \"\\nAnswer:\"\n",
    "    if include_answer:\n",
    "        prompt += f\" {df.iloc[idx, num_choices + 1]}\"\n",
    "    prompt += \"\\n\\n\"\n",
    "    return prompt\n",
    "\n",
    "def get_subcategories_by_selected_categories(selected_categories):\n",
    "    \"\"\"\n",
    "    Retrieves all subcategories that fall under the selected higher-level categories.\n",
    "\n",
    "    Args:\n",
    "        selected_categories (list): List of higher-level category names.\n",
    "\n",
    "    Returns:\n",
    "        set: Set of subcategory names that belong to the selected categories.\n",
    "    \"\"\"\n",
    "    selected_subcategories = set()\n",
    "    for high_cat in selected_categories:\n",
    "        if high_cat not in CATEGORIES:\n",
    "            print(f\"Warning: High-level category '{high_cat}' not recognized. Skipping.\")\n",
    "            continue\n",
    "        categories_in_high_cat = CATEGORIES[high_cat]\n",
    "        for subcat, cats in SUBCATEGORIES.items():\n",
    "            for cat in cats:\n",
    "                if cat in categories_in_high_cat:\n",
    "                    selected_subcategories.add(subcat)\n",
    "    return selected_subcategories\n",
    "\n",
    "def collect_attack_prompts(data_dir, selected_subcategories, ntrain=5):\n",
    "    \"\"\"\n",
    "    Collects prompts from selected subcategories and aggregates them into a list.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the data directory containing 'dev' and 'test' folders.\n",
    "        selected_subcategories (set): Set of subcategory names to include.\n",
    "        ntrain (int): Number of training examples to include from the dev set.\n",
    "\n",
    "    Returns:\n",
    "        list: Aggregated list of formatted prompts.\n",
    "    \"\"\"\n",
    "    attack_prompts = []\n",
    "    \n",
    "    for subcat in selected_subcategories:\n",
    "        dev_path = os.path.join(data_dir, \"dev\", f\"{subcat}_dev.csv\")\n",
    "        test_path = os.path.join(data_dir, \"test\", f\"{subcat}_test.csv\")\n",
    "        \n",
    "        # Check if both dev and test files exist\n",
    "        if not os.path.isfile(dev_path):\n",
    "            print(f\"Development file for '{subcat}' not found at {dev_path}. Skipping this subcategory.\")\n",
    "            continue\n",
    "        if not os.path.isfile(test_path):\n",
    "            print(f\"Test file for '{subcat}' not found at {test_path}. Skipping this subcategory.\")\n",
    "            continue\n",
    "        \n",
    "        # Load the CSV files\n",
    "        dev_df = pd.read_csv(dev_path, header=None)\n",
    "        test_df = pd.read_csv(test_path, header=None)\n",
    "        \n",
    "        # Limit the number of training examples if specified\n",
    "        if ntrain > 0:\n",
    "            dev_df = dev_df.iloc[:ntrain]\n",
    "        \n",
    "        # Collect prompts from the dev set\n",
    "        for i in range(dev_df.shape[0]):\n",
    "            prompt = format_example(dev_df, i, include_answer=True)\n",
    "            attack_prompts.append(prompt)\n",
    "        \n",
    "        # Collect prompts from the test set\n",
    "        for i in range(test_df.shape[0]):\n",
    "            prompt = format_example(test_df, i, include_answer=True)\n",
    "            attack_prompts.append(prompt)\n",
    "        \n",
    "        print(f\"Collected {dev_df.shape[0] + test_df.shape[0]} prompts from subcategory '{subcat}'.\")\n",
    "    \n",
    "    print(f\"\\nTotal prompts collected: {len(attack_prompts)}\")\n",
    "    return attack_prompts\n",
    "\n",
    "def save_attack_prompts(attack_prompts, save_path):\n",
    "    \"\"\"\n",
    "    Saves the aggregated attack prompts to a text file.\n",
    "\n",
    "    Args:\n",
    "        attack_prompts (list): List of formatted prompts.\n",
    "        save_path (str): Path to save the attack prompts file.\n",
    "    \"\"\"\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for prompt in attack_prompts:\n",
    "            f.write(prompt + \"\\n\")\n",
    "    print(f\"Attack prompts saved to {save_path}\")\n",
    "\n",
    "def main():\n",
    "    # Argument parser for command-line options\n",
    "    parser = argparse.ArgumentParser(description=\"Process MMLU data into attack_prompts list based on selected categories.\")\n",
    "    parser.add_argument(\n",
    "        \"--data-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory containing the 'dev' and 'test' subdirectories with CSV files.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save-file\",\n",
    "        type=str,\n",
    "        default=\"attack_prompts.txt\",\n",
    "        help=\"File path to save the aggregated attack prompts.\"\n",
    "    )\n",
    "    group = parser.add_mutually_exclusive_group(required=True)\n",
    "    group.add_argument(\n",
    "        \"--selected-subcategories\",\n",
    "        type=str,\n",
    "        nargs='+',\n",
    "        help=\"List of subcategory names to include (e.g., physics mathematics).\"\n",
    "    )\n",
    "    group.add_argument(\n",
    "        \"--selected-categories\",\n",
    "        type=str,\n",
    "        nargs='+',\n",
    "        help=\"List of higher-level category names to include (e.g., STEM humanities).\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ntrain\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"Number of training examples to include from each subcategory's dev set.\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Determine which subcategories to include\n",
    "    if args.selected_categories:\n",
    "        selected_categories = args.selected_categories\n",
    "        selected_subcategories = get_subcategories_by_selected_categories(selected_categories)\n",
    "        if not selected_subcategories:\n",
    "            print(\"No valid subcategories found for the selected categories. Exiting.\")\n",
    "            return\n",
    "    else:\n",
    "        selected_subcategories = set(args.selected_subcategories)\n",
    "    \n",
    "    print(f\"Selected subcategories: {selected_subcategories}\")\n",
    "    \n",
    "    # Collect attack prompts\n",
    "    attack_prompts = collect_attack_prompts(\n",
    "        data_dir=args.data_dir,\n",
    "        selected_subcategories=selected_subcategories,\n",
    "        ntrain=args.ntrain\n",
    "    )\n",
    "    \n",
    "    # Save the attack prompts to a file\n",
    "    save_attack_prompts(attack_prompts, args.save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "def compute_accuracies(data):\n",
    "    \"\"\"\n",
    "    计算每个子类别、每个类别以及整体的准确率。\n",
    "\n",
    "    Args:\n",
    "        data (list): 数据条目列表。\n",
    "\n",
    "    Returns:\n",
    "        tuple: 包含子类别准确率、类别准确率和整体准确率的三个字典。\n",
    "    \"\"\"\n",
    "    # 初始化字典以存储计数\n",
    "    subcat_counts = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "    cat_counts = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "\n",
    "    # 初始化整体计数\n",
    "    overall_total = 0\n",
    "    overall_correct = 0\n",
    "\n",
    "    for entry in data:\n",
    "        category = entry.get('category', ['Unknown'])[0]  # 假设category是一个列表\n",
    "        subcategory = entry.get('subcategory', 'Unknown')\n",
    "        correct_answer = entry.get('answer', '').strip().upper()\n",
    "        output = entry.get('output', '')\n",
    "        predicted_answer = output[3].strip().upper() if output else ''\n",
    "\n",
    "        # 更新子类别计数\n",
    "        subcat_counts[subcategory]['total'] += 1\n",
    "        if predicted_answer == correct_answer:\n",
    "            subcat_counts[subcategory]['correct'] += 1\n",
    "\n",
    "        # 更新类别计数\n",
    "        cat_counts[category]['total'] += 1\n",
    "        if predicted_answer == correct_answer:\n",
    "            cat_counts[category]['correct'] += 1\n",
    "\n",
    "        # 更新整体计数\n",
    "        overall_total += 1\n",
    "        if predicted_answer == correct_answer:\n",
    "            overall_correct += 1\n",
    "\n",
    "    # 计算子类别准确率\n",
    "    subcat_accuracy = {}\n",
    "    for subcat, counts in subcat_counts.items():\n",
    "        total = counts['total']\n",
    "        correct = counts['correct']\n",
    "        accuracy = (correct / total) * 100 if total > 0 else 0.0\n",
    "        subcat_accuracy[subcat] = round(accuracy, 2)\n",
    "\n",
    "    # 计算类别准确率\n",
    "    cat_accuracy = {}\n",
    "    for cat, counts in cat_counts.items():\n",
    "        total = counts['total']\n",
    "        correct = counts['correct']\n",
    "        accuracy = (correct / total) * 100 if total > 0 else 0.0\n",
    "        cat_accuracy[cat] = round(accuracy, 2)\n",
    "\n",
    "    # 计算整体准确率\n",
    "    overall_accuracy = (overall_correct / overall_total) * 100 if overall_total > 0 else 0.0\n",
    "    overall_accuracy = round(overall_accuracy, 2)\n",
    "\n",
    "    return subcat_accuracy, cat_accuracy, overall_accuracy\n",
    "\n",
    "def save_accuracies(subcat_accuracy, cat_accuracy, overall_accuracy, folder_path, save_name, output_file='accuracies.json'):\n",
    "    \"\"\"\n",
    "    将子类别准确率、类别准确率和整体准确率保存到同一个 JSON 文件中。\n",
    "\n",
    "    Args:\n",
    "        subcat_accuracy (dict): 每个子类别的准确率。\n",
    "        cat_accuracy (dict): 每个类别的准确率。\n",
    "        overall_accuracy (float): 整体准确率。\n",
    "        folder_path (str): 保存文件的文件夹路径。\n",
    "        save_name (str): 保存文件的前缀名称。\n",
    "        output_file (str): 输出 JSON 文件名（默认 'accuracies.json'）。\n",
    "    \"\"\"\n",
    "    # 确保保存文件的文件夹存在\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # 构建完整的文件路径\n",
    "    output_path = os.path.join(folder_path, f\"{save_name}_{output_file}\")\n",
    "\n",
    "    # 构建要保存的字典\n",
    "    accuracies = {\n",
    "        \"subcategory_accuracy\": subcat_accuracy,\n",
    "        \"category_accuracy\": cat_accuracy,\n",
    "        \"overall_accuracy\": overall_accuracy\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # 保存所有准确率到一个 JSON 文件\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(accuracies, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"所有准确率已保存到 '{output_path}'.\")\n",
    "    except IOError as e:\n",
    "        print(f\"保存准确率时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有准确率已保存到 './SafeDecoding_mistral_MMLU_accuracies.json'.\n"
     ]
    }
   ],
   "source": [
    " \n",
    "with open('/home/kz34/Yang_Ouyang_Projects/ICLR2025/jailbreaking_related/SafeDecoding/exp_outputs_new_new_new/SafeDecoding_mistral_MMLU_7723_2024-11-25 08:50:38/SafeDecoding_mistral_MMLU_7723_2024-11-25 08:50:38.json', 'r') as f:\n",
    "    output_json = json.load(f)\n",
    "results = output_json['data']\n",
    "subcat_acc, cat_acc, overall_acc = compute_accuracies(results)\n",
    "save_accuracies(subcat_acc, cat_acc, overall_acc, './', \"SafeDecoding_mistral_MMLU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdvBench_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
